{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11239552,"sourceType":"datasetVersion","datasetId":7006196}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### VGG-16 Architecture","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T02:15:19.217263Z","iopub.execute_input":"2025-09-14T02:15:19.217518Z","iopub.status.idle":"2025-09-14T02:15:19.222365Z","shell.execute_reply.started":"2025-09-14T02:15:19.217494Z","shell.execute_reply":"2025-09-14T02:15:19.221569Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Enable CUDA error tracing (optional)\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\n# Define your device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Parameters\nimg_size = 224\nbatch_size = 16\nnum_epochs = 100\ndata_dir = \"/kaggle/input/brain-cancer-mri-dataset/Brain_Cancer raw MRI data/Brain_Cancer\"\n\n# Data transforms (normalization using ImageNet stats)\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean\n                         std=[0.229, 0.224, 0.225])   # ImageNet std\n])\n\n# Load dataset\ndataset = datasets.ImageFolder(data_dir, transform=transform)\ntargets = [sample[1] for sample in dataset.samples]\n\n# Split train and validation indices\ntrain_idx, val_idx = train_test_split(\n    list(range(len(dataset))),\n    stratify=targets,\n    test_size=0.2,\n    random_state=42\n)\n\ntrain_dataset = Subset(dataset, train_idx)\nval_dataset = Subset(dataset, val_idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# Define the model using pretrained VGG16\nclass VGG16FineTuner(nn.Module):\n    def __init__(self, num_classes):\n        super(VGG16FineTuner, self).__init__()\n        base_model = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT)\n        self.features = base_model.features\n        \n        # Freeze feature extractor (optional)\n        for param in self.features.parameters():\n            param.requires_grad = False\n        \n        # Classifier head\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),  # Global average pooling\n            nn.Flatten(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nnum_classes = len(dataset.classes)\nmodel = VGG16FineTuner(num_classes).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    correct = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n\n    train_acc = correct / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n\n    # Validation\n    model.eval()\n    val_correct = 0\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    val_acc = val_correct / len(val_loader.dataset)\n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n\n# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=dataset.classes))\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(7,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=dataset.classes,\n            yticklabels=dataset.classes)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.savefig(\"CM_VGG16.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get number of classes and class names\nnum_classes = len(dataset.classes)\nclass_names = dataset.classes\n\n# Collect true labels and predicted probabilities on validation set\nmodel.eval()\ny_true = []\ny_probs = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)              # raw logits\n        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n\n        y_true.extend(labels.cpu().numpy())\n        y_probs.extend(probs.cpu().numpy())\n\ny_true = np.array(y_true)\ny_probs = np.array(y_probs)\n\n# Binarize true labels for ROC\ny_true_bin = label_binarize(y_true, classes=range(num_classes))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\ncolors = plt.cm.get_cmap('Set1', num_classes)\n\nfor i, color in zip(range(num_classes), colors.colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curves for Multi-class Brain Tumor Classification')\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.savefig(\"ROC_VGG116.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    correct = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n\n    epoch_train_loss = total_loss / len(train_loader.dataset)\n    epoch_train_acc = correct / len(train_loader.dataset)\n\n    train_losses.append(epoch_train_loss)\n    train_accuracies.append(epoch_train_acc)\n\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n\n    epoch_val_loss = val_loss / len(val_loader.dataset)\n    epoch_val_acc = val_correct / len(val_loader.dataset)\n\n    val_losses.append(epoch_val_loss)\n    val_accuracies.append(epoch_val_acc)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n          f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.4f} | \"\n          f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = range(1, num_epochs + 1)\n\nplt.figure(figsize=(12,5))\n\nplt.subplot(1,2,1)\nplt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\nplt.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(epochs, train_losses, 'b-', label='Training Loss')\nplt.plot(epochs, val_losses, 'r-', label='Validation Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig(\"Accuracy_Loss CURVE.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}