{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11239552,"sourceType":"datasetVersion","datasetId":7006196}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### MedAttnNet Architecture","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SE Block\nclass SEBlock(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SEBlock, self).__init__()\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.global_avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n# Transformer Block\nclass TransformerBlock(nn.Module):\n    def __init__(self, d_model=2048, nhead=8, dim_feedforward=2048):\n        super(TransformerBlock, self).__init__()\n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward\n        )\n        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        x = x.view(b, c, -1).permute(2, 0, 1)  # (HW, B, C)\n        x = self.transformer(x)\n        x = x.permute(1, 2, 0).view(b, c, h, w)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MedAttnNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(MedAttnNet, self).__init__()\n        base_model = models.resnet50(pretrained=True)\n        self.stem = nn.Sequential(\n            base_model.conv1,\n            base_model.bn1,\n            base_model.relu,\n            base_model.maxpool\n        )\n\n        self.layer1 = nn.Sequential(base_model.layer1, SEBlock(256))\n        self.layer2 = nn.Sequential(base_model.layer2, SEBlock(512))\n        self.layer3 = nn.Sequential(base_model.layer3, SEBlock(1024))\n        self.layer4 = nn.Sequential(base_model.layer4, SEBlock(2048))\n\n        self.transformer = TransformerBlock(d_model=2048)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(2048, num_classes)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.transformer(x)\n        x = self.pool(x).view(x.size(0), -1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/brain-cancer-mri-dataset/Brain_Cancer raw MRI data/Brain_Cancer'\nbatch_size = 16\nimg_size = 224\n\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\ndataset = datasets.ImageFolder(data_dir, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset.classes)        # e.g., ['glioma', 'meningioma', 'no_tumor']\nprint(dataset.class_to_idx)   # e.g., {'glioma': 0, 'meningioma': 1, 'no_tumor': 2}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Enable CUDA error tracing\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\n# SE Block with safe reduction\nclass SEBlock(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SEBlock, self).__init__()\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, max(1, channel // reduction)),\n            nn.ReLU(inplace=True),\n            nn.Linear(max(1, channel // reduction), channel),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.global_avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n# Transformer Block with batch_first=True\nclass TransformerBlock(nn.Module):\n    def __init__(self, d_model=2048, nhead=8, dim_feedforward=2048):\n        super(TransformerBlock, self).__init__()\n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        x = x.view(b, c, -1).permute(0, 2, 1)  # (B, HW, C)\n        x = self.transformer(x)\n        x = x.permute(0, 2, 1).view(b, c, h, w)\n        return x\n\n# MedAttnNet Model\nclass MedAttnNet(nn.Module):\n    def __init__(self, num_classes=3):\n        super(MedAttnNet, self).__init__()\n        base_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n        self.stem = nn.Sequential(\n            base_model.conv1,\n            base_model.bn1,\n            base_model.relu,\n            base_model.maxpool\n        )\n\n        self.layer1 = nn.Sequential(base_model.layer1, SEBlock(256))\n        self.layer2 = nn.Sequential(base_model.layer2, SEBlock(512))\n        self.layer3 = nn.Sequential(base_model.layer3, SEBlock(1024))\n        self.layer4 = nn.Sequential(base_model.layer4, SEBlock(2048))\n\n        self.transformer = TransformerBlock(d_model=2048)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(2048, num_classes)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.transformer(x)\n        x = self.pool(x).view(x.size(0), -1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n\n# Data loading\nimg_size = 224\nbatch_size = 16\ndata_dir = \"/kaggle/input/brain-cancer-mri-dataset/Brain_Cancer raw MRI data/Brain_Cancer\"\n\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\ndataset = datasets.ImageFolder(data_dir, transform=transform)\ntargets = [sample[1] for sample in dataset.samples]\ntrain_idx, val_idx = train_test_split(list(range(len(dataset))), stratify=targets, test_size=0.2, random_state=42)\n\ntrain_dataset = Subset(dataset, train_idx)\nval_dataset = Subset(dataset, val_idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MedAttnNet(num_classes=3).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    correct = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n\n    acc = 100 * correct / len(train_loader.dataset)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%\")\n\n# Evaluation\nmodel.eval()\ny_true, y_pred = [], []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        y_true.extend(labels.numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\nprint(classification_report(y_true, y_pred, target_names=dataset.classes))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=dataset.classes, yticklabels=dataset.classes, cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    # -------- Training --------\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).long()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    train_loss = running_loss / total\n    train_acc = 100 * correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    # -------- Validation --------\n    model.eval()\n    val_running_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device).long()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_loss = val_running_loss / val_total\n    val_acc = 100 * val_correct / val_total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n\n    # Print epoch metrics\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset.classes)\nplt.figure(figsize=(6, 5))\ndisp.plot(cmap='Blues', values_format='d')\nplt.title(\"Confusion Matrix\")\nplt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Number of classes\nnum_classes = len(dataset.classes)\n\n# Convert labels to one-hot encoding\ny_true_onehot = label_binarize(y_true, classes=range(num_classes))\n\n# Get predicted probabilities\ny_score = []\nmodel.eval()\nwith torch.no_grad():\n    for images, _ in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        y_score.extend(F.softmax(outputs, dim=1).cpu().numpy())\n\ny_score = np.array(y_score)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_true_onehot[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\ncolors = ['blue', 'green', 'red']\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n             label=f'ROC curve (class {dataset.classes[i]}) AUC = {roc_auc[i]:.2f}')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Multi-Class ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.grid()\nplt.savefig(\"ROC.png\", dpi=300, bbox_inches='tight')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport pandas as pd\n\n# Generate classification report\nreport = classification_report(y_true, y_pred, target_names=dataset.classes, output_dict=True)\n\n# Convert to DataFrame\ndf_report = pd.DataFrame(report).transpose()\n\n# Display the table\nprint(df_report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}